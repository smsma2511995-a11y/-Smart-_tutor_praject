# core/cache_system.py
import pickle
import hashlib
from datetime import datetime, timedelta
from pathlib import Path

class SmartCache:
    def __init__(self, cache_dir="data/cache", max_size_mb=100, ttl_hours=24):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.max_size = max_size_mb * 1024 * 1024  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¨Ø§ÙŠØª
        self.ttl = timedelta(hours=ttl_hours)
        
        self.clean_expired()
    
    def get_cache_key(self, question: str, subject: str = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯ Ù„Ù„Ø³Ø¤Ø§Ù„"""
        content = f"{question}_{subject}" if subject else question
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get(self, question: str, subject: str = None):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        cache_key = self.get_cache_key(question, subject)
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'rb') as f:
                cached_data = pickle.load(f)
            
            # ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
            if datetime.now() - cached_data['timestamp'] > self.ttl:
                cache_file.unlink()  # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ù†ØªÙ‡ÙŠ
                return None
            
            return cached_data['answer']
        except:
            return None
    
    def set(self, question: str, answer: dict, subject: str = None):
        """Ø­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        cache_key = self.get_cache_key(question, subject)
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        cache_data = {
            'question': question,
            'subject': subject,
            'answer': answer,
            'timestamp': datetime.now()
        }
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            
            # Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø­Ø¬Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            self.manage_cache_size()
            
            return True
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return False
    
    def manage_cache_size(self):
        """Ø¥Ø¯Ø§Ø±Ø© Ø­Ø¬Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        cache_files = list(self.cache_dir.glob("*.pkl"))
        
        if not cache_files:
            return
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ÙƒÙ„ÙŠ
        total_size = sum(f.stat().st_size for f in cache_files)
        
        if total_size > self.max_size:
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ù‚Ø¯Ù…
            cache_files_sorted = sorted(cache_files, key=lambda f: f.stat().st_mtime)
            files_to_delete = cache_files_sorted[:len(cache_files_sorted) // 4]  # Ø­Ø°Ù 25% Ø§Ù„Ø£Ù‚Ø¯Ù…
            
            for file in files_to_delete:
                file.unlink()
            
            print(f"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ø­Ø°Ù {len(files_to_delete)} Ù…Ù„Ù")
    
    def clean_expired(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"""
        cache_files = list(self.cache_dir.glob("*.pkl"))
        now = datetime.now()
        expired_count = 0
        
        for cache_file in cache_files:
            try:
                with open(cache_file, 'rb') as f:
                    cached_data = pickle.load(f)
                
                if now - cached_data['timestamp'] > self.ttl:
                    cache_file.unlink()
                    expired_count += 1
            except:
                cache_file.unlink()  # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù
        
        if expired_count > 0:
            print(f"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ {expired_count} Ù…Ù„Ù Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©")
    
    def get_stats(self):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        cache_files = list(self.cache_dir.glob("*.pkl"))
        total_size = sum(f.stat().st_size for f in cache_files)
        
        return {
            "total_files": len(cache_files),
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "hit_rate": self.calculate_hit_rate()
        }
