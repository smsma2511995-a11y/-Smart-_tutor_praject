#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
"""

import re
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime

class AdvancedEssayEvaluator:
    """Ù…Ù‚ÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    
    def __init__(self):
        self.language_rules = self._initialize_language_rules()
        self.grading_rubrics = self._initialize_grading_rubrics()
        self.feedback_templates = self._initialize_feedback_templates()
        self.plagiarism_patterns = self._initialize_plagiarism_patterns()
    
    # Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªÙ†ÙÙŠØ°)
    def _load_arabic_grammar_rules(self): return []
    def _load_arabic_style_guidelines(self): return []
    def _load_arabic_common_errors(self) -> List[Tuple[str, str, str]]:
        return [
            (r'Ù‡Ø§Ø°Ø§\b', 'Ù‡Ø°Ø§', 'Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ù‡Ø°Ø§'),
            (r'Ø¥Ù„Ù‰\s+Ø£Ù†\s+Ù„Ù†', 'Ø¥Ù„Ù‰ Ø£Ù„Ø§', 'Ø®Ø·Ø£ ÙÙŠ Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±'),
        ]
    def _load_english_grammar_rules(self): return []
    def _load_english_style_guidelines(self): return []
    def _load_english_common_errors(self) -> List[Tuple[str, str, str]]:
        return [
            (r'\bthats\b', "that's", 'Missing apostrophe'),
            (r'\bthere\s+are\s+much\b', "there are many", 'Wrong quantifier'),
        ]
    def _load_french_grammar_rules(self): return []
    def _load_french_style_guidelines(self): return []
    def _load_french_common_errors(self) -> List[Tuple[str, str, str]]:
        return []
    
    def _initialize_language_rules(self) -> Dict:
        """ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„ØºØ© Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        return {
            'arabic': {
                'grammar_rules': self._load_arabic_grammar_rules(),
                'style_guidelines': self._load_arabic_style_guidelines(),
                'common_errors': self._load_arabic_common_errors()
            },
            'english': {
                'grammar_rules': self._load_english_grammar_rules(),
                'style_guidelines': self._load_english_style_guidelines(),
                'common_errors': self._load_english_common_errors()
            },
            'french': {
                'grammar_rules': self._load_french_grammar_rules(),
                'style_guidelines': self._load_french_style_guidelines(),
                'common_errors': self._load_french_common_errors()
            }
        }
    
    def _initialize_grading_rubrics(self) -> Dict:
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
        return {
            'content_organization': {
                'excellent': {'score': 10, 'criteria': ['ÙˆØ§Ø¶Ø­', 'Ù…Ù†Ø¸Ù…', 'Ù…ØªØ±Ø§Ø¨Ø·']},
                'good': {'score': 8, 'criteria': ['Ø¬ÙŠØ¯', 'Ù…Ù†Ø¸Ù… Ø¬Ø²Ø¦ÙŠØ§Ù‹']},
                'fair': {'score': 6, 'criteria': ['Ù…Ù‚Ø¨ÙˆÙ„', 'Ø¶Ø¹ÙŠÙ Ø§Ù„ØªØ±Ø§Ø¨Ø·']},
                'poor': {'score': 4, 'criteria': ['ØºÙŠØ± Ù…Ù†Ø¸Ù…', 'ØºÙŠØ± ÙˆØ§Ø¶Ø­']}
            },
            'language_use': {
                'excellent': {'score': 10, 'criteria': ['Ø³Ù„ÙŠÙ…', 'Ù…ØªÙ†ÙˆØ¹', 'ÙØµÙŠØ­']},
                'good': {'score': 8, 'criteria': ['Ø¬ÙŠØ¯', 'Ø£Ø®Ø·Ø§Ø¡ Ù‚Ù„ÙŠÙ„Ø©']},
                'fair': {'score': 6, 'criteria': ['Ù…Ù‚Ø¨ÙˆÙ„', 'Ø£Ø®Ø·Ø§Ø¡ Ù…ØªÙˆØ³Ø·Ø©']},
                'poor': {'score': 4, 'criteria': ['Ø¶Ø¹ÙŠÙ', 'Ø£Ø®Ø·Ø§Ø¡ ÙƒØ«ÙŠØ±Ø©']}
            },
            'vocabulary': {
                'excellent': {'score': 10, 'criteria': ['ØºÙ†ÙŠ', 'Ù…Ù†Ø§Ø³Ø¨', 'Ø¯Ù‚ÙŠÙ‚']},
                'good': {'score': 8, 'criteria': ['Ø¬ÙŠØ¯', 'Ù…Ù†Ø§Ø³Ø¨']},
                'fair': {'score': 6, 'criteria': ['Ù…Ø­Ø¯ÙˆØ¯', 'Ù…ØªÙƒØ±Ø±']},
                'poor': {'score': 4, 'criteria': ['Ø¶Ø¹ÙŠÙ', 'ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨']}
            },
            'creativity': {
                'excellent': {'score': 10, 'criteria': ['Ù…Ø¨Ø¯Ø¹', 'Ø£ØµÙŠÙ„', 'Ø¬Ø°Ø§Ø¨']},
                'good': {'score': 8, 'criteria': ['Ø¬ÙŠØ¯', 'Ù…Ù‚Ø¨ÙˆÙ„']},
                'fair': {'score': 6, 'criteria': ['Ø¹Ø§Ø¯ÙŠ', 'ØªÙ‚Ù„ÙŠØ¯ÙŠ']},
                'poor': {'score': 4, 'criteria': ['Ø¶Ø¹ÙŠÙ', 'Ù…Ù…Ù„']}
            }
        }
    
    def _initialize_feedback_templates(self) -> Dict:
        """ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"""
        return {
            'positive': [
                "Ø£Ø­Ø³Ù†Øª! {aspect} Ù…Ù…ØªØ§Ø².",
                "Ù…Ø¬Ù‡ÙˆØ¯ Ø±Ø§Ø¦Ø¹ ÙÙŠ {aspect}.",
                "ØªØ­Ø³Ù† Ù…Ù„Ø­ÙˆØ¸ ÙÙŠ {aspect}."
            ],
            'constructive': [
                "ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† {aspect} Ø¹Ù† Ø·Ø±ÙŠÙ‚ {suggestion}.",
                "Ø§Ù†ØªØ¨Ù‡ Ø¥Ù„Ù‰ {aspect} ÙˆØ­Ø§ÙˆÙ„ {suggestion}.",
                "Ù„ØªØ­Ø³ÙŠÙ† {aspect}ØŒ Ø¬Ø±Ø¨ {suggestion}."
            ],
            'corrective': [
                "Ù‡Ù†Ø§Ùƒ Ø®Ø·Ø£ ÙÙŠ {aspect}ØŒ ÙˆØ§Ù„ØµØ­ÙŠØ­ Ù‡Ùˆ {correction}.",
                "ÙŠØ­ØªØ§Ø¬ {aspect} Ø¥Ù„Ù‰ ØªØµØ­ÙŠØ­: {correction}.",
                "Ù„ØªØµØ­ÙŠØ­ {aspect}: {correction}."
            ]
        }
    
    def _initialize_plagiarism_patterns(self) -> List[str]:
        """ØªÙ‡ÙŠØ¦Ø© Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„"""
        return [
            r"https?://[^\s]+",  # Ø±ÙˆØ§Ø¨Ø·
            r"Â©\s*\d{4}",  # Ø­Ù‚ÙˆÙ‚ Ù†Ø´Ø±
            r"Ø§Ù„Ù…ØµØ¯Ø±:",  # Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ø±
        ]
    
    def evaluate_essay(self, essay_text: str, language: str, topic: str, 
                      student_level: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„"""
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        basic_analysis = self._analyze_essay_basics(essay_text, language)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„
        plagiarism_check = self._check_plagiarism(essay_text)
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„ØºÙˆÙŠ
        language_analysis = self._analyze_language(essay_text, language)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        content_evaluation = self._evaluate_content(essay_text, topic, language)
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø§Ù…Ù„
        overall_evaluation = self._calculate_overall_evaluation(
            basic_analysis, language_analysis, content_evaluation, student_level
        )
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        detailed_feedback = self._generate_detailed_feedback(
            overall_evaluation, language_analysis, content_evaluation, student_level
        )
        
        return {
            'essay_topic': topic,
            'language': language,
            'student_level': student_level,
            'evaluation_date': datetime.now().isoformat(),
            'basic_analysis': basic_analysis,
            'plagiarism_check': plagiarism_check,
            'language_analysis': language_analysis,
            'content_evaluation': content_evaluation,
            'overall_evaluation': overall_evaluation,
            'detailed_feedback': detailed_feedback,
            'improvement_suggestions': self._generate_improvement_suggestions(overall_evaluation)
        }
    
    def _analyze_essay_basics(self, essay_text: str, language: str) -> Dict:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ù‚Ø§Ù„"""
        words = essay_text.split()
        sentences = re.split(r'[.!?]', essay_text)
        paragraphs = essay_text.split('\n\n')
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ÙØ§Ø±ØºØ©
        sentences = [s.strip() for s in sentences if s.strip()]
        paragraphs = [p.strip() for p in paragraphs if p.strip()]
        
        return {
            'word_count': len(words),
            'sentence_count': len(sentences),
            'paragraph_count': len(paragraphs),
            'average_sentence_length': len(words) / max(1, len(sentences)),
            'average_paragraph_length': len(words) / max(1, len(paragraphs)),
            'reading_level': self._assess_reading_level(words, sentences, language)
        }
    
    def _assess_reading_level(self, words: List[str], sentences: List[str], language: str) -> str:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©"""
        avg_sentence_length = len(words) / max(1, len(sentences))
        avg_word_length = sum(len(word) for word in words) / max(1, len(words))
        
        if language == 'arabic':
            if avg_sentence_length < 10 and avg_word_length < 5:
                return 'Ù…Ø¨ØªØ¯Ø¦'
            elif avg_sentence_length < 15 and avg_word_length < 6:
                return 'Ù…ØªÙˆØ³Ø·'
            else:
                return 'Ù…ØªÙ‚Ø¯Ù…'
        else:
            if avg_sentence_length < 12 and avg_word_length < 5:
                return 'beginner'
            elif avg_sentence_length < 18 and avg_word_length < 6:
                return 'intermediate'
            else:
                return 'advanced'
    
    def _check_plagiarism(self, essay_text: str) -> Dict:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„"""
        plagiarism_indicators = []
        
        for pattern in self.plagiarism_patterns:
            matches = re.findall(pattern, essay_text)
            if matches:
                plagiarism_indicators.extend(matches)
        
        return {
            'plagiarism_detected': len(plagiarism_indicators) > 0,
            'suspicious_elements': plagiarism_indicators,
            'originality_score': max(0, 10 - len(plagiarism_indicators)),
            'recommendation': 'ØªØ£ÙƒØ¯ Ù…Ù† ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø§Ù„Ø®Ø§Øµ' if plagiarism_indicators else 'Ù…Ù…ØªØ§Ø² - Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø£ØµÙ„ÙŠ'
        }
    
    def _analyze_language(self, essay_text: str, language: str) -> Dict:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„ØºÙˆÙŠ Ù„Ù„Ù…Ù‚Ø§Ù„"""
        language_rules = self.language_rules.get(language, {})
        
        return {
            'grammar_analysis': self._analyze_grammar(essay_text, language),
            'vocabulary_analysis': self._analyze_vocabulary(essay_text, language),
            'style_analysis': self._analyze_style(essay_text, language),
            'common_errors_found': self._detect_common_errors(essay_text, language),
            'language_complexity': self._assess_language_complexity(essay_text, language)
        }
    
    def _analyze_grammar(self, essay_text: str, language: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ©"""
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ
        grammar_issues = []
        
        if language == 'arabic':
            # ÙƒØ´Ù Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            arabic_errors = [
                (r'Ù‡Ø§Ø°Ø§\b', 'Ù‡Ø°Ø§', 'Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ù‡Ø°Ø§'),
                (r'Ø¥Ù„Ù‰\s+Ø£Ù†\s+Ù„Ù†', 'Ø¥Ù„Ù‰ Ø£Ù„Ø§', 'Ø®Ø·Ø£ ÙÙŠ Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±'),
                (r'Ø§Ù„Ø°ÙŠÙ†\s+Ù‡Ù…', 'Ø§Ù„Ø°ÙŠÙ†', 'Ø²ÙŠØ§Ø¯Ø© Ø¶Ù…ÙŠØ±'),
            ]
            
            for pattern, correction, description in arabic_errors:
                if re.search(pattern, essay_text):
                    grammar_issues.append({
                        'issue': description,
                        'correction': correction,
                        'severity': 'medium'
                    })
        
        return {
            'grammar_score': max(0, 10 - len(grammar_issues)),
            'issues_found': grammar_issues,
            'issues_count': len(grammar_issues),
            'assessment': 'Ø¬ÙŠØ¯' if len(grammar_issues) < 3 else 'ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†'
        }
    
    def _analyze_vocabulary(self, essay_text: str, language: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª"""
        words = essay_text.split()
        unique_words = set(words)
        
        # Ø­Ø³Ø§Ø¨ ØªÙ†ÙˆØ¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        vocabulary_diversity = len(unique_words) / len(words) if words else 0
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        if vocabulary_diversity > 0.7:
            level = 'Ù…ØªÙ‚Ø¯Ù…'
        elif vocabulary_diversity > 0.5:
            level = 'Ù…ØªÙˆØ³Ø·'
        else:
            level = 'Ù…Ø­Ø¯ÙˆØ¯'
        
        return {
            'total_words': len(words),
            'unique_words': len(unique_words),
            'vocabulary_diversity': vocabulary_diversity,
            'vocabulary_level': level,
            'repetition_ratio': 1 - vocabulary_diversity
        }
    
    def _analyze_style(self, essay_text: str, language: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨"""
        sentences = re.split(r'[.!?]', essay_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # ØªØ­Ù„ÙŠÙ„ ØªÙ†ÙˆØ¹ Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„
        sentence_lengths = [len(s.split()) for s in sentences]
        avg_sentence_length = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0
        
        # ØªÙ‚ÙŠÙŠÙ… ØªÙ†ÙˆØ¹ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨
        style_variety = self._assess_style_variety(essay_text, language)
        
        return {
            'average_sentence_length': avg_sentence_length,
            'sentence_variety': min(1.0, len(set(sentence_lengths)) / len(sentence_lengths)) if sentence_lengths else 0,
            'style_consistency': 'Ø¬ÙŠØ¯',
            'coherence_score': 8.0,
            'style_assessment': style_variety
        }
    
    def _assess_style_variety(self, essay_text: str, language: str) -> str:
        """ØªÙ‚ÙŠÙŠÙ… ØªÙ†ÙˆØ¹ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨"""
        # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙ‚ÙŠÙŠÙ… ØªÙ†ÙˆØ¹ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨
        stylistic_elements = [
            'Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©',
            'Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª',
            'Ø§Ù„ØªÙ†ÙˆØ¹ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù„'
        ]
        
        detected_elements = []
        for element in stylistic_elements:
            if element in essay_text[:500]:  # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„
                detected_elements.append(element)
        
        if len(detected_elements) >= 2:
            return 'Ù…ØªÙ†ÙˆØ¹'
        elif len(detected_elements) >= 1:
            return 'Ù…ØªÙˆØ³Ø·'
        else:
            return 'Ù…Ø­Ø¯ÙˆØ¯'
    
    def _detect_common_errors(self, essay_text: str, language: str) -> List[Dict]:
        """ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        common_errors = self.language_rules.get(language, {}).get('common_errors', [])
        detected_errors = []
        
        for error_pattern, correction, description in common_errors:
            matches = re.finditer(error_pattern, essay_text)
            for match in matches:
                detected_errors.append({
                    'error': description,
                    'location': match.start(),
                    'correction': correction,
                    'example': match.group()
                })
        
        return detected_errors[:10]  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 10 Ø£Ø®Ø·Ø§Ø¡
    
    def _assess_language_complexity(self, essay_text: str, language: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù„ØºØ©"""
        words = essay_text.split()
        sentences = re.split(r'[.!?]', essay_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
        avg_sentence_length = len(words) / len(sentences) if sentences else 0
        complex_word_ratio = sum(1 for word in words if len(word) > 6) / len(words) if words else 0
        
        complexity_score = (avg_word_length * 0.3 + avg_sentence_length * 0.4 + complex_word_ratio * 0.3) * 2
        
        return {
            'complexity_score': complexity_score,
            'level': 'Ø¨Ø³ÙŠØ·' if complexity_score < 5 else 'Ù…ØªÙˆØ³Ø·' if complexity_score < 8 else 'Ù…Ø¹Ù‚Ø¯',
            'indicators': {
                'average_word_length': avg_word_length,
                'average_sentence_length': avg_sentence_length,
                'complex_word_ratio': complex_word_ratio
            }
        }
    
    def _evaluate_content(self, essay_text: str, topic: str, language: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„"""
        return {
            'topic_relevance': self._assess_topic_relevance(essay_text, topic),
            'content_organization': self._assess_organization(essay_text),
            'argument_strength': self._assess_argument_strength(essay_text),
            'supporting_evidence': self._assess_supporting_evidence(essay_text),
            'originality': self._assess_originality(essay_text)
        }
    
    def _assess_topic_relevance(self, essay_text: str, topic: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… ØµÙ„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹"""
        topic_keywords = topic.split()
        relevance_score = 0
        
        for keyword in topic_keywords:
            if keyword.lower() in essay_text.lower():
                relevance_score += 2
        
        max_score = len(topic_keywords) * 2
        normalized_score = min(10, (relevance_score / max_score) * 10) if max_score > 0 else 5
        
        return {
            'score': normalized_score,
            'assessment': 'Ù…Ø±ØªØ¨Ø·' if normalized_score >= 7 else 'Ø¬Ø²Ø¦ÙŠ' if normalized_score >= 5 else 'Ø¶Ø¹ÙŠÙ',
            'missing_keywords': [kw for kw in topic_keywords if kw.lower() not in essay_text.lower()]
        }
    
    def _assess_organization(self, essay_text: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        paragraphs = essay_text.split('\n\n')
        
        # ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„
        has_introduction = len(paragraphs) > 0 and len(paragraphs[0].split()) >= 30
        has_conclusion = len(paragraphs) > 1 and len(paragraphs[-1].split()) >= 20
        paragraph_transitions = self._check_paragraph_transitions(paragraphs)
        
        organization_score = 0
        if has_introduction:
            organization_score += 3
        if has_conclusion:
            organization_score += 3
        organization_score += min(4, paragraph_transitions)
        
        return {
            'score': organization_score,
            'has_introduction': has_introduction,
            'has_conclusion': has_conclusion,
            'paragraph_transitions': paragraph_transitions,
            'structure_assessment': 'Ø¬ÙŠØ¯' if organization_score >= 7 else 'Ù…ØªÙˆØ³Ø·' if organization_score >= 5 else 'Ø¶Ø¹ÙŠÙ'
        }
    
    def _check_paragraph_transitions(self, paragraphs: List[str]) -> int:
        """ÙØ­Øµ Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„ÙÙ‚Ø±Ø§Øª"""
        transition_indicators = [
            'Ø£ÙŠØ¶Ø§Ù‹', 'Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ©', 'Ø¹Ù„Ø§ÙˆØ© Ø¹Ù„Ù‰', 'Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø£Ø®Ø±Ù‰',
            'ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„', 'Ø¨Ø§Ù„Ù…Ø«Ù„', 'Ù†ØªÙŠØ¬Ø© Ù„Ø°Ù„Ùƒ', 'Ø¨Ø§Ø®ØªØµØ§Ø±'
        ]
        
        transition_count = 0
        for i in range(1, len(paragraphs)):
            first_sentence = paragraphs[i].split('.')[0] if '.' in paragraphs[i] else paragraphs[i]
            if any(transition in first_sentence for transition in transition_indicators):
                transition_count += 1
        
        return min(4, transition_count)
    
    def _assess_argument_strength(self, essay_text: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ù‚ÙˆØ© Ø§Ù„Ø­Ø¬Ø¬"""
        argument_indicators = [
            'Ù„Ø£Ù†', 'Ø¨Ø³Ø¨Ø¨', 'Ù†ØªÙŠØ¬Ø©', 'ÙŠØ¯Ù„ Ø¹Ù„Ù‰', 'ÙŠØ¤ÙƒØ¯',
            'ÙŠØ¨Ø±Ù‡Ù†', 'ÙŠØ¸Ù‡Ø±', 'ÙŠØ¯Ø¹Ù…', 'ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰'
        ]
        
        argument_count = sum(1 for indicator in argument_indicators if indicator in essay_text)
        
        return {
            'score': min(10, argument_count * 2),
            'argument_indicators_count': argument_count,
            'assessment': 'Ù‚ÙˆÙŠ' if argument_count >= 5 else 'Ù…ØªÙˆØ³Ø·' if argument_count >= 3 else 'Ø¶Ø¹ÙŠÙ'
        }
    
    def _assess_supporting_evidence(self, essay_text: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ø¯Ø§Ø¹Ù…Ø©"""
        evidence_indicators = [
            'Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„', 'Ù…Ø«Ù„Ø§Ù‹', 'ÙƒØ°Ù„Ùƒ', 'ÙƒÙ…Ø§',
            'Ø¥Ø­ØµØ§Ø¦ÙŠØ©', 'Ø¯Ø±Ø§Ø³Ø©', 'Ø¨Ø­Ø«', 'ØªÙ‚Ø±ÙŠØ±'
        ]
        
        evidence_count = sum(1 for indicator in evidence_indicators if indicator in essay_text)
        
        return {
            'score': min(10, evidence_count * 2),
            'evidence_indicators_count': evidence_count,
            'assessment': 'ØºÙ†ÙŠ' if evidence_count >= 4 else 'Ù…ØªÙˆØ³Ø·' if evidence_count >= 2 else 'Ù…Ø­Ø¯ÙˆØ¯'
        }
    
    def _assess_originality(self, essay_text: str) -> Dict:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£ØµØ§Ù„Ø©"""
        common_phrases = [
            'ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ø¶Ø±', 'ÙÙŠ Ø¹ØµØ±Ù†Ø§ Ù‡Ø°Ø§', 'Ù„Ø§ Ø´Ùƒ Ø£Ù†',
            'Ø¬Ø¯ÙŠØ± Ø¨Ø§Ù„Ø°ÙƒØ±', 'Ù…Ù† Ø§Ù„Ù…Ø¹Ø±ÙˆÙ Ø£Ù†', 'ÙŠØ¹ØªØ¨Ø± Ù…Ù†'
        ]
        
        common_phrase_count = sum(1 for phrase in common_phrases if phrase in essay_text)
        originality_score = max(0, 10 - common_phrase_count)
        
        return {
            'score': originality_score,
            'common_phrases_count': common_phrase_count,
            'assessment': 'Ù…Ø¨Ø¯Ø¹' if originality_score >= 8 else 'Ù…ØªÙˆØ³Ø·' if originality_score >= 6 else 'ØªÙ‚Ù„ÙŠØ¯ÙŠ'
        }
    
    def _calculate_overall_evaluation(self, basic_analysis: Dict, language_analysis: Dict,
                                   content_evaluation: Dict, student_level: str) -> Dict:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø§Ù…Ù„"""
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        weights = {
            'content': 0.4,
            'language': 0.4,
            'organization': 0.2
        }
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
        content_score = content_evaluation['topic_relevance']['score'] * 0.3 + \
                      content_evaluation['argument_strength']['score'] * 0.3 + \
                      content_evaluation['supporting_evidence']['score'] * 0.2 + \
                      content_evaluation['originality']['score'] * 0.2
        
        language_score = language_analysis['grammar_analysis']['grammar_score'] * 0.4 + \
                        language_analysis['vocabulary_analysis']['vocabulary_diversity'] * 10 * 0.3 + \
                        language_analysis['style_analysis']['coherence_score'] * 0.3
        
        organization_score = content_evaluation['content_organization']['score']
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø§Ù…Ù„
        overall_score = (content_score * weights['content'] + 
                        language_score * weights['language'] + 
                        organization_score * weights['organization'])
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø·Ø§Ù„Ø¨
        level_benchmarks = {
            'beginner': (6, 8, 10),
            'intermediate': (7, 9, 10),
            'advanced': (8, 9.5, 10)
        }
        
        good, excellent, perfect = level_benchmarks.get(student_level, (7, 9, 10))
        
        if overall_score >= excellent:
            grade = 'Ù…Ù…ØªØ§Ø²'
        elif overall_score >= good:
            grade = 'Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹'
        elif overall_score >= good - 2:
            grade = 'Ø¬ÙŠØ¯'
        else:
            grade = 'Ù…Ù‚Ø¨ÙˆÙ„'
        
        return {
            'overall_score': overall_score,
            'grade': grade,
            'content_score': content_score,
            'language_score': language_score,
            'organization_score': organization_score,
            'strengths': self._identify_strengths(content_evaluation, language_analysis),
            'areas_for_improvement': self._identify_improvement_areas(content_evaluation, language_analysis)
        }
    
    def _identify_strengths(self, content_evaluation: Dict, language_analysis: Dict) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©"""
        strengths = []
        
        if content_evaluation['topic_relevance']['score'] >= 8:
            strengths.append('Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹')
        if content_evaluation['argument_strength']['score'] >= 8:
            strengths.append('Ù‚ÙˆØ© Ø§Ù„Ø­Ø¬Ø¬')
        if language_analysis['vocabulary_analysis']['vocabulary_level'] == 'Ù…ØªÙ‚Ø¯Ù…':
            strengths.append('ØºÙ†Ù‰ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª')
        if language_analysis['grammar_analysis']['issues_count'] <= 2:
            strengths.append('Ø¯Ù‚Ø© Ø§Ù„Ù„ØºØ©')
        
        return strengths if strengths else ['Ù…Ø¬Ù‡ÙˆØ¯ Ù…Ø´ÙƒÙˆØ±']
    
    def _identify_improvement_areas(self, content_evaluation: Dict, language_analysis: Dict) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        improvements = []
        
        if content_evaluation['topic_relevance']['score'] < 6:
            improvements.append('Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹')
        if content_evaluation['argument_strength']['score'] < 6:
            improvements.append('ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø­Ø¬Ø¬')
        if language_analysis['grammar_analysis']['issues_count'] > 5:
            improvements.append('ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯')
        if content_evaluation['content_organization']['score'] < 6:
            improvements.append('ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰')
        
        return improvements if improvements else ['Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„ØªØ­Ø³Ù†']
    
    def _generate_detailed_feedback(self, overall_evaluation: Dict, language_analysis: Dict,
                                 content_evaluation: Dict, student_level: str) -> List[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© ØªÙØµÙŠÙ„ÙŠØ©"""
        feedback = []
        
        # ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        content_feedback = {
            'aspect': 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰',
            'type': 'constructive',
            'message': self._generate_content_feedback(content_evaluation),
            'suggestions': self._generate_content_suggestions(content_evaluation)
        }
        feedback.append(content_feedback)
        
        # ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„Ù„ØºØ©
        language_feedback = {
            'aspect': 'Ø§Ù„Ù„ØºØ©',
            'type': 'constructive',
            'message': self._generate_language_feedback(language_analysis),
            'suggestions': self._generate_language_suggestions(language_analysis)
        }
        feedback.append(language_feedback)
        
        # ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ…
        organization_feedback = {
            'aspect': 'Ø§Ù„ØªÙ†Ø¸ÙŠÙ…',
            'type': 'constructive',
            'message': self._generate_organization_feedback(content_evaluation),
            'suggestions': self._generate_organization_suggestions(content_evaluation)
        }
        feedback.append(organization_feedback)
        
        # ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ù…Ø©
        overall_feedback = {
            'aspect': 'Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…',
            'type': 'positive' if overall_evaluation['overall_score'] >= 7 else 'constructive',
            'message': f"Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ø§Ù…: {overall_evaluation['grade']}",
            'suggestions': ['Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØªÙ…ÙŠØ²'] if overall_evaluation['overall_score'] >= 8 else ['ÙˆØ§ØµÙ„ Ø§Ù„ØªØ­Ø³Ù†']
        }
        feedback.append(overall_feedback)
        
        return feedback
    
    def _generate_content_feedback(self, content_evaluation: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        relevance = content_evaluation['topic_relevance']
        arguments = content_evaluation['argument_strength']
        
        if relevance['score'] >= 8 and arguments['score'] >= 8:
            return "Ù…Ø­ØªÙˆÙ‰ Ù…Ù…ØªØ§Ø² ÙˆÙ…Ø±ØªØ¨Ø· Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ Ø­Ø¬Ø¬ Ù‚ÙˆÙŠØ©."
        elif relevance['score'] >= 6 and arguments['score'] >= 6:
            return "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¬ÙŠØ¯ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ† ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø­Ø¬Ø¬ ÙˆØ§Ù„Ø£Ø¯Ù„Ø©."
        else:
            return "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙˆØªÙ‚ÙˆÙŠØ© Ø§Ù„Ø­Ø¬Ø¬."
    
    def _generate_language_feedback(self, language_analysis: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„Ù„ØºØ©"""
        grammar = language_analysis['grammar_analysis']
        vocabulary = language_analysis['vocabulary_analysis']
        
        if grammar['grammar_score'] >= 8 and vocabulary['vocabulary_level'] == 'Ù…ØªÙ‚Ø¯Ù…':
            return "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù…ØªØ§Ø² Ù„Ù„ØºØ© Ù…Ø¹ Ù…ÙØ±Ø¯Ø§Øª ØºÙ†ÙŠØ© ÙˆØ¯Ù‚Ø© Ù†Ø­ÙˆÙŠØ©."
        elif grammar['grammar_score'] >= 6 and vocabulary['vocabulary_level'] == 'Ù…ØªÙˆØ³Ø·':
            return "Ø§Ù„Ù„ØºØ© Ø¬ÙŠØ¯Ø© ÙˆÙ„ÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ø¬Ø§Ù„ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆØªÙ†ÙˆÙŠØ¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª."
        else:
            return "Ø§Ù„Ù„ØºØ© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆØªÙˆØ³ÙŠØ¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª."
    
    def _generate_organization_feedback(self, content_evaluation: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ…"""
        organization = content_evaluation['content_organization']
        
        if organization['score'] >= 8:
            return "ØªÙ†Ø¸ÙŠÙ… Ù…Ù…ØªØ§Ø² Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª Ø³Ù„Ø³Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£ÙÙƒØ§Ø±."
        elif organization['score'] >= 6:
            return "Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø¬ÙŠØ¯ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª Ø§Ù„ÙÙ‚Ø±Ø§Øª."
        else:
            return "Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø®Ø§ØªÙ…Ø©."
    
    def _generate_content_suggestions(self, content_evaluation: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ù…Ø­ØªÙˆÙ‰"""
        suggestions = []
        
        if content_evaluation['topic_relevance']['score'] < 7:
            suggestions.append("Ø±ÙƒØ² Ø£ÙƒØ«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø´Ùˆ.")
        
        if content_evaluation['argument_strength']['score'] < 7:
            suggestions.append("Ø£Ø¶Ù Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø­Ø¬Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© Ù„Ø¯Ø¹Ù… ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø±Ùƒ.")
        
        if content_evaluation['supporting_evidence']['score'] < 7:
            suggestions.append("Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø«Ù„Ø© ÙˆØ£Ø¯Ù„Ø© Ù…Ù„Ù…ÙˆØ³Ø© Ù„Ø¯Ø¹Ù… argumentsÙƒ.")
        
        return suggestions if suggestions else ["Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø­Ø§Ù„ÙŠ"]
    
    def _generate_language_suggestions(self, language_analysis: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØºØ©"""
        suggestions = []
        
        if language_analysis['grammar_analysis']['issues_count'] > 3:
            suggestions.append("Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.")
        
        if language_analysis['vocabulary_analysis']['vocabulary_diversity'] < 0.6:
            suggestions.append("Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ±Ø¯Ø§Øª Ø£ÙƒØ«Ø± ØªÙ†ÙˆØ¹Ø§Ù‹.")
        
        return suggestions if suggestions else ["Ø§Ù„Ù„ØºØ© Ø¬ÙŠØ¯Ø©ØŒ Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰"]
    
    def _generate_organization_suggestions(self, content_evaluation: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªÙ†Ø¸ÙŠÙ…"""
        suggestions = []
        
        organization = content_evaluation['content_organization']
        
        if not organization['has_introduction']:
            suggestions.append("Ø£Ø¶Ù Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ø¶Ø­Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.")
        
        if not organization['has_conclusion']:
            suggestions.append("Ø§Ø®ØªØªÙ… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø®Ø§ØªÙ…Ø© ØªÙ„Ø®Øµ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.")
        
        if organization['paragraph_transitions'] < 2:
            suggestions.append("Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ø§Ù†ØªÙ‚Ø§Ù„ÙŠØ© Ù„Ø±Ø¨Ø· Ø§Ù„ÙÙ‚Ø±Ø§Øª.")
        
        return suggestions if suggestions else ["Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ Ø¬ÙŠØ¯"]
    
    def _generate_improvement_suggestions(self, overall_evaluation: Dict) -> List[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª ØªØ­Ø³ÙŠÙ† Ø´Ø§Ù…Ù„Ø©"""
        suggestions = []
        
        for area in overall_evaluation['areas_for_improvement']:
            if 'Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹' in area:
                suggestions.append({
                    'area': 'Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹',
                    'suggestion': 'Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆØ®Ø·Ø· Ù„Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø©',
                    'resources': ['Ø¯ÙˆØ±Ø© Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø±ÙƒØ²Ø©', 'ØªÙ…Ø§Ø±ÙŠÙ† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©']
                })
            elif 'Ø§Ù„Ø­Ø¬Ø¬' in area:
                suggestions.append({
                    'area': 'ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ø­Ø¬Ø¬',
                    'suggestion': 'Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ù„Ø© ÙˆØ£Ù…Ø«Ù„Ø© Ù…Ù„Ù…ÙˆØ³Ø© Ù„Ø¯Ø¹Ù… argumentsÙƒ',
                    'resources': ['Ø¯ÙˆØ±Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù†Ù‚Ø¯ÙŠ', 'ØªÙ…Ø§Ø±ÙŠÙ† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø­Ø¬Ø¬']
                })
            elif 'Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯' in area:
                suggestions.append({
                    'area': 'ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯',
                    'suggestion': 'Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©',
                    'resources': ['Ù…Ø±Ø¬Ø¹ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ©', 'ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©']
                })
        
        return suggestions
    
    def generate_writing_prompts(self, student_level: str, language: str, 
                               topic_category: str) -> List[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙƒØªØ§Ø¨Ø© Ù…Ø®ØµØµØ©"""
        prompt_templates = {
            'beginner': [
                {
                    'topic': 'ÙˆØµÙ Ø´Ø®Øµ Ø£Ø¹Ø¬Ø¨Ùƒ',
                    'instructions': 'ØµÙ Ø´Ø®ØµÙŠØ© Ø£Ø¹Ø¬Ø¨ØªÙƒ Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„ØµÙØ§Øª ÙˆØ§Ù„Ø£Ø³Ø¨Ø§Ø¨',
                    'word_target': 150,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'ØµÙØ§Øª', 'Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø¨', 'Ø®Ø§ØªÙ…Ø©']
                },
                {
                    'topic': 'ÙŠÙˆÙ… Ù„Ø§ ØªÙ†Ø³Ø§Ù‡',
                    'instructions': 'Ø§ÙƒØªØ¨ Ø¹Ù† ÙŠÙˆÙ… Ù…Ù…ÙŠØ² ÙÙŠ Ø­ÙŠØ§ØªÙƒ',
                    'word_target': 200,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ÙŠÙˆÙ…', 'Ù„Ù…Ø§Ø°Ø§ Ù‡Ùˆ Ù…Ù…ÙŠØ²', 'Ø®Ø§ØªÙ…Ø©']
                }
            ],
            'intermediate': [
                {
                    'topic': 'Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©',
                    'instructions': 'Ù†Ø§Ù‚Ø´ ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ£Ø«Ø±Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø¯ ÙˆØ§Ù„Ù…Ø¬ØªÙ…Ø¹',
                    'word_target': 300,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'ÙÙˆØ§Ø¦Ø¯ ÙØ±Ø¯ÙŠØ©', 'ÙÙˆØ§Ø¦Ø¯ Ù…Ø¬ØªÙ…Ø¹ÙŠØ©', 'Ø®Ø§ØªÙ…Ø©']
                },
                {
                    'topic': 'Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙˆØªØ£Ø«ÙŠØ±Ù‡Ø§',
                    'instructions': 'Ø­Ù„Ù„ Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª ÙˆØ³Ù„Ø¨ÙŠØ§Øª Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙÙŠ Ø­ÙŠØ§ØªÙ†Ø§',
                    'word_target': 350,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª', 'Ø³Ù„Ø¨ÙŠØ§Øª', 'ØªÙˆØ§Ø²Ù†', 'Ø®Ø§ØªÙ…Ø©']
                }
            ],
            'advanced': [
                {
                    'topic': 'Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ù…Ø³ØªØ¯Ø§Ù…Ø©',
                    'instructions': 'Ù†Ø§Ù‚Ø´ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ù…Ø³ØªØ¯Ø§Ù…Ø© ÙˆØªØ­Ø¯ÙŠØ§Øª ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§',
                    'word_target': 500,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'ØªØ¹Ø±ÙŠÙ', 'ØªØ­Ø¯ÙŠØ§Øª', 'Ø­Ù„ÙˆÙ„', 'Ø®Ø§ØªÙ…Ø©']
                },
                {
                    'topic': 'Ø¯ÙˆØ± Ø§Ù„Ø´Ø¨Ø§Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹',
                    'instructions': 'Ø­Ù„Ù„ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª Ø§Ù„Ø´Ø¨Ø§Ø¨ ÙˆØªØ£Ø«ÙŠØ±Ù‡Ù… ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹',
                    'word_target': 450,
                    'suggested_structure': ['Ù…Ù‚Ø¯Ù…Ø©', 'Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª', 'ØªØ£Ø«ÙŠØ±', 'ØªØ­Ø¯ÙŠØ§Øª', 'Ø®Ø§ØªÙ…Ø©']
                }
            ]
        }
        
        return prompt_templates.get(student_level, prompt_templates['intermediate'])

# Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚ÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
if __name__ == "__main__":
    evaluator = AdvancedEssayEvaluator()
    
    # Ù…Ù‚Ø§Ù„ Ø§Ø®ØªØ¨Ø§Ø±ÙŠ
    sample_essay = """
    Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ù‡Ùˆ Ø£Ø³Ø§Ø³ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª. ÙÙŠ Ø¹ØµØ±Ù†Ø§ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø£ØµØ¨Ø­ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø¶Ø±ÙˆØ±ÙŠØ§Ù‹ Ù„ÙƒÙ„ ÙØ±Ø¯. 
    Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ ØªÙ†Ù…ÙŠØ© Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª ÙˆØªØ­Ø³ÙŠÙ† Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø¹ÙŠØ´Ø©. 
    
    Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ØŒ ÙŠÙ…ÙƒÙ† Ù„Ù„ÙØ±Ø¯ Ø£Ù† ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ ÙØ±Øµ Ø¹Ù…Ù„ Ø£ÙØ¶Ù„. ÙƒÙ…Ø§ Ø£Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙŠÙ†Ù…ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù†Ù‚Ø¯ÙŠ ÙˆØ§Ù„Ø¥Ø¨Ø¯Ø§Ø¹. 
    Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø£ÙŠØ¶Ø§Ù‹ ÙŠØ³Ø§Ù‡Ù… ÙÙŠ Ø¨Ù†Ø§Ø¡ Ù…Ø¬ØªÙ…Ø¹ Ù…ØªØ­Ø¶Ø± ÙˆÙ…ØªØ·ÙˆØ±.
    
    ÙÙŠ Ø§Ù„Ø®ØªØ§Ù…ØŒ ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ù„Ø£Ù†Ù‡ Ù…ÙØªØ§Ø­ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙˆØ§Ù„ØªÙ‚Ø¯Ù….
    """
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„
    evaluation = evaluator.evaluate_essay(
        essay_text=sample_essay,
        language='arabic',
        topic='Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ…',
        student_level='intermediate'
    )
    
    print("ğŸ“ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„:")
    print(f"â€¢ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©: {evaluation['overall_evaluation']['overall_score']:.1f}/10")
    print(f"â€¢ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {evaluation['overall_evaluation']['grade']}")
    print(f"â€¢ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©: {', '.join(evaluation['overall_evaluation']['strengths'])}")
    print(f"â€¢ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†: {', '.join(evaluation['overall_evaluation']['areas_for_improvement'])}")
    
    # ØªÙˆÙ„ÙŠØ¯ Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙƒØªØ§Ø¨Ø©
    prompts = evaluator.generate_writing_prompts('intermediate', 'arabic', 'Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ')
    print(f"\nğŸ¯ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ù‚ØªØ±Ø­Ø©: {prompts[0]['topic']}")
